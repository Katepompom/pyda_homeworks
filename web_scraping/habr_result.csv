,date,title,link,text
0,2021-06-01 15:00:00,Как учить протоколы без чтения RFC: как сэкономить время при разработке,https://habr.com/ru/company/macloud/blog/560406/,"<div class=""post__text post__text-html post__text_v1"" id=""post-content-body""><img src=""https://habrastorage.org/webt/g7/2o/g0/g72og0nkmjoonhewn-zkbhnil_8.png""/><br/>
<br/>
Если вы разрабатывает приложение, работающее по сети, или проводите отладку работы такого приложения, доскональное знание работы сетевых протоколов сильно облегчит вашу задачу. Первоисточником подобного знания являются RFC и, к счастью, они с давних времен находятся в открытом доступе. Более того, прочитать их можно даже консольных браузером links, так как кроме текста в них ничего не содержится.<br/>
<br/>
Тем не менее, скорее всего большинство читателей Хабра никогда не читали полностью текст хотя бы одного RFC, даже <a href=""https://www.rfc-editor.org/rfc/rfc2616.txt"">RFC-2616</a>. Помимо зубодробительного стиля бюрократических документов, помехой может служить языковой барьер. К тому же чаще всего нужно понять какой-то определенный аспект архитектуры протокола: длину и тип полей, код возврата, расположение внутри заголовка. Для этого вовсе не обязательно читать все от корки до корки.<br/>
<br/>
Как раз для этого случая написан <i>Protocol</i>, довольно простое консольное приложение, написанное на Python. Оно имеет двоякое назначение.<br/>
<br/>
<ul>
<li>Предоставить разработчикам и инженерам возможность легко и просто увидеть диаграмму заголовков самых распространенных сетевых протоколов прямиком из командной строки.</li>
<li>Предоставить исследователям и инженерам возможность быстро создавать ASCII диаграммы заголовков, для своих собственных пользовательских протоколов.</li>
</ul><a name=""habracut""></a><br/>
<h2>Установка и настройка</h2><br/>
Исходный код находится <a href=""https://github.com/luismartingarcia/protocol"">на GitHub</a>, скачать можно стандартным способом.<br/>
<br/>
<pre><code class=""bash"">git clone https://github.com/luismartingarcia/protocol.git
</code></pre><br/>
Настройка производится командой с правами пользователя root.<br/>
<br/>
<pre><code class=""bash"">setup.py install</code></pre><br/>
Так как программа на данный момент не имеет стандартного механизма установки дистрибутивов Linux, или Python, лучше запомнить куда копируются файлы.<br/>
<br/>
<pre><code class=""bash"">running install

running build

running build_scripts

creating build

creating build/scripts-3.9

copying and adjusting protocol -&gt; build/scripts-3.9

copying constants.py -&gt; build/scripts-3.9

copying specs.py -&gt; build/scripts-3.9

changing mode of build/scripts-3.9/protocol from 644 to 755

changing mode of build/scripts-3.9/constants.py from 644 to 755

changing mode of build/scripts-3.9/specs.py from 644 to 755

running install_scripts

copying build/scripts-3.9/protocol -&gt; /usr/bin

copying build/scripts-3.9/constants.py -&gt; /usr/bin

copying build/scripts-3.9/specs.py -&gt; /usr/bin

changing mode of /usr/bin/protocol to 755

changing mode of /usr/bin/constants.py to 755

changing mode of /usr/bin/specs.py to 755

running install_egg_info

Writing /usr/lib/python3.9/site-packages/protocol-0.1-py3.9.egg-info</code></pre><br/>
<h2>Запускаем protocol</h2><br/>
У программы имеются два основных режима работы:<br/>
<br/>
<ol>
<li>protocol &lt;название существующего протокола&gt;;</li>
<li>protocol &lt;спецификации собственного протокола&gt;.</li>
</ol><br/>
Доступны следующие стандартные протоколы<br/>
<br/>
<pre><code class=""bash"">ethernet            : Ethernet

8021q               : IEEE 802.1q

dot1q               : IEEE 802.1q

tcp                 : Transmission Control Protocol (TCP)

udp                 : User Datagram Protocol (TCP)

ip                  : Internet Protocol (IP), version 4.

ipv6                : Internet Protocol (IP), version 6.

icmp                : Internet Control Message Protocol (ICMP)

icmp-destination:   : ICMP Destination Unreachable

icmp-time           : ICMP Time Exceeded

icmp-parameter      : ICMP Parameter Problem

icmp-source         : ICMP Source Quench

icmp-redirect       : ICMP Redirect

icmp-echo           : ICMP Echo Request/Reply

icmp-timestamp      : ICMP Timestamp Request/Reply

icmp-information    : ICMP Information Request/Reply

icmpv6              : ICMP for IPv6 (ICMPv6)

icmpv6-destination  : ICMPv6 Destination Unreachable

icmpv6-big          : ICMPv6 Packet Too Big

icmpv6-time         : ICMPv6 Time Exceeded

icmpv6-parameter    : ICMPv6 Parameter Problem

icmpv6-echo         : ICMPv6 Echo Request/Reply

icmpv6-rsol         : ICMPv6 Router Solicitation

icmpv6-radv         : ICMPv6 Router Advertisement

icmpv6-nsol         : ICMPv6 Neighbor Solicitation

icmpv6-nadv         : ICMPv6 Neighbor Advertisement

icmpv6-redirect     : ICMPv6 Redirect</code></pre><br/>
Вот примеры использования утилиты.<br/>
<br/>
<pre><code class=""bash"">|12:09:41|admin@redeye:[~]&gt; protocol ip

 0                   1                   2                   3

 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|Version|  IHL  |Type of Service|          Total Length         |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|         Identification        |Flags|     Fragment Offset     |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|  Time to Live |    Protocol   |        Header Checksum        |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|                         Source Address                        |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|                      Destination Address                      |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|                    Options                    |    Padding    |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|12:09:45|admin@redeye:[~]&gt; protocol ipv6

 0                   1                   2                   3

 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|Version| Traffic Class |               Flow Label              |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|         Payload Length        |  Next Header  |   Hop Limit   |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|                                                               |

+                                                               +

|                                                               |

+                         Source Address                        +

|                                                               |

+                                                               +

|                                                               |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|                                                               |

+                                                               +

|                                                               |

+                       Destination Address                     +

|                                                               |

+                                                               +

|                                                               |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+</code></pre><br/>
<br/>
В одной команде можно указать сразу несколько протоколов, разделив их пробелом.<br/>
<br/>
<pre><code class=""bash"">|12:34:16|admin@redeye:[~]&gt; protocol icmp-time icmp-timestamp

 0                   1                   2                   3

 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|      Type     |      Code     |            Checksum           |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|                             Unused                            |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|                                                               |

+      Internet Header + 64 bits of Original Data Datagram      +

|                                                               |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 0                   1                   2                   3

 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|      Type     |      Code     |            Checksum           |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|           Identifier          |        Sequence Number        |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|                      Originate Timestamp                      |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|                       Receive Timestamp                       |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|                       Transmit Timestamp                      |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+</code></pre><br/>
Protocol догадлив, не обязательно набирать название протокола полностью, если уж совсем лень можно например вместо dot1q набрать dot. Однако, как в случае с автодополнением, при неоднозначном выборе предлагается выбрать одну из альтернатив.<br/>
<br/>
<pre><code class=""bash"">|12:43:25|admin@redeye:[~]&gt; protocol icmpv6-r

Ambiguous protocol specifier 'icmpv6-r'. Did you mean any of these?

  icmpv6-radv

  icmpv6-redirect

  icmpv6-rsol
</code></pre><br/>
<h2>Собственные разработки</h2><br/>
Наиболее важной чертой спецификации протокола являются списки полей. Можно указать их для собственного протокола следующим образом.<br/>
<br/>
<pre><code class=""bash"">|12:55:16|mikayel@redeye:[~]&gt; protocol «Source:16,Reserved:40,RTT:8»

 0                   1                   2                   3

 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|             Source            |                               |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+               +-+-+-+-+-+-+-+-+

|                    Reserved                   |      RTT      |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+</code></pre><br/>
Дополнительные опции расширяют возможности форматирования ASCII диаграммы. Можно указать количество битов на линию, задать символы для разделителя и псевдографики. Предыдущая команда с опциями псевдодографики выдаст следующее.<br/>
<br/>
<pre><code class=""bash"">|16:02:05|mikayel@redeye:[~]&gt; protocol «Source:16,Reserved:40,RTT:8?\

  numbers=y,startchar=*,endchar=*,evenchar=-,oddchar=-,sepchar=|»

 0                   1                   2                   3  

 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

*---------------------------------------------------------------*

|             Source            |                               |

*-------------------------------*               *---------------*

|                    Reserved                   |      RTT      |

*---------------------------------------------------------------*
</code></pre><br/>
<h2>Protocol + tshark</h2><br/>
Более полную информацию по структуре сетевых протоколов можно получить, открыв в <i>tshark</i> сохраненный pcap/pcapng файл сетевого трафика. Если смотреть только в <i>tshark</i> можно за деревьями не заметить леса, а вместе с <i>Protocol</i> — то что надо.<br/>
<br/>
<pre><code class=""bash"">|16:08:05|admin@redeye:[~]&gt; sudo tshark -r /tmp/exmp.pcap -V

Transmission Control Protocol, Src Port: 48378, Dst Port: 443, Seq: 1, Ack: 1, Len: 0

    Source Port: 48378

    Destination Port: 443

    [Stream index: 0]

    [TCP Segment Len: 0]

    Sequence Number: 1    (relative sequence number)

    Sequence Number (raw): 1120003294

    [Next Sequence Number: 1    (relative sequence number)]

    Acknowledgment Number: 1    (relative ack number)

    Acknowledgment number (raw): 4090007166

    1000 .... = Header Length: 32 bytes (8)

    Flags: 0x010 (ACK)

        000. .... .... = Reserved: Not set

        ...0 .... .... = Nonce: Not set

        .... 0... .... = Congestion Window Reduced (CWR): Not set

        .... .0.. .... = ECN-Echo: Not set

        .... ..0. .... = Urgent: Not set

        .... ...1 .... = Acknowledgment: Set

        .... .... 0... = Push: Not set

        .... .... .0.. = Reset: Not set

        .... .... ..0. = Syn: Not set

        .... .... ...0 = Fin: Not set

        [TCP Flags: ·······A····]

    Window: 501

    [Calculated window size: 501]

    [Window size scaling factor: -1 (unknown)]

    Checksum: 0xfbe8 [unverified]

    [Checksum Status: Unverified]

    Urgent Pointer: 0

    Options: (12 bytes), No-Operation (NOP), No-Operation (NOP), Timestamps

        TCP Option — No-Operation (NOP)

            Kind: No-Operation (1)

        TCP Option — No-Operation (NOP)

            Kind: No-Operation (1)

        TCP Option — Timestamps: TSval 2014817649, TSecr 2606727549

            Kind: Time Stamp Option (8)

            Length: 10

            Timestamp value: 2014817649

            Timestamp echo reply: 2606727549

|16:28:51|admin@redeye:[~]&gt; protocol tcp

 0                   1                   2                   3

 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|          Source Port          |        Destination Port       |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|                        Sequence Number                        |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|                     Acknowledgment Number                     |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

| Offset|  Res. |     Flags     |             Window            |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|            Checksum           |         Urgent Pointer        |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

|                    Options                    |    Padding    |

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
</code></pre><br/>
Конечно такие программы, как Protocol, и tshark не могут и не должны заменить собой чтение первоисточников, т․ е․ RFC, однако они позволяют сильно сэкономить время программистов и системных администраторов.<br/>
<br/>
<hr/><br/>
Облачные серверы от <a href=""https://macloud.ru/?partner=4189mjxpzx"">Маклауд</a> быстрые и безопасные.<br/>
<br/>
Зарегистрируйтесь по ссылке выше или кликнув на баннер и получите 10% скидку на первый месяц аренды сервера любой конфигурации!<br/>
<br/>
<a href=""https://macloud.ru/?partner=4189mjxpzx&amp;utm_source=habr&amp;utm_medium=original&amp;utm_campaign=mikael""><img src=""https://habrastorage.org/webt/et/1a/yp/et1aypandyuamqprsz3m2ntm4ky.png""/></a></div>"
1,2021-06-01 12:22:00,Как Apache Spark 3.0 увеличивает производительность ваших SQL рабочих нагрузок,https://habr.com/ru/company/cloudera/blog/560246/,"<div class=""post__text post__text_v2"" id=""post-content-body""><figure class=""""><img height=""400"" src=""https://habrastorage.org/getpro/habr/upload_files/11c/566/323/11c566323b6ec3f11034b3b03af7ca4f.png"" width=""1382""/><figcaption></figcaption></figure><p>Практически в каждом секторе, работающем со сложными данными, Spark ""де-факто"" быстро стал средой распределенных вычислений для команд на всех этапах жизненного цикла данных и аналитики. Одна из наиболее ожидаемых функций Spark 3.0 - это новая платформа Adaptive Query Execution (AQE), устраняющая проблемы, которые возникают при многих рабочих нагрузках Spark SQL. Они были <a href=""https://software.intel.com/content/www/us/en/develop/articles/spark-sql-adaptive-execution-at-100-tb.html"">задокументированы</a> в начале 2018 года командой специалистов Intel и Baidu. Для более глубокого изучения фреймворка можно пройти наш обновленный курс по тюнингу производительности Apache Spark (<a href=""https://www.cloudera.com/about/training/courses/advanced-spark-application-performance-tuning.html"">Apache Spark Performance Tuning</a>).</p><p>Наш опыт работы с <a href=""https://www.cloudera.com/products/workload-xm.html"">Workload XM</a>, безусловно, подтверждает реальность и серьезность этих проблем.</p><p>AQE был впервые представлен в Spark 2.4, но в Spark 3.0 и 3.1 он стал намного более развитым. Для начала, давайте посмотрим, какие проблемы решает AQE.</p><h3>Недостаток первоначальной архитектуры Catalyst </h3><p>На диаграмме ниже представлен вид распределенной обработки, которая происходит, когда вы выполняете простой group-by-count  запрос с использованием DataFrames.</p><figure class=""""><img height=""480"" src=""https://habrastorage.org/getpro/habr/upload_files/123/4b4/910/1234b49104ae93ff31e967e65a8468d7.png"" width=""1600""/><figcaption></figcaption></figure><p>Spark определяет подходящее количество партиций для первого этапа, но для второго этапа использует по умолчанию ""магическое число"" - 200.</p><p>И это плохо по трем причинам: </p><p>1. 200 вряд ли будет идеальным количеством партиций, а именно их количество является одним из критических факторов, влияющих на производительность;</p><p>2. Если вы запишете результат этого второго этапа на диск, у вас может получиться 200 маленьких файлов;</p><p>3. Оптимизация и ее отсутствие имеют косвенный эффект: если обработка должна продолжаться после второго этапа, то вы можете упустить потенциальные возможности дополнительной оптимизации.</p><p>Что можно сделать? Вручную установить значение этого свойства перед выполнением запроса с помощью такого оператора:</p><p>spark.conf.set(“spark.sql.shuffle.partitions”,”2″)</p><p>Но это также создает некоторые проблемы:</p><ul><li><p>Задавать данный параметр перед каждым запросом утомительно.</p></li><li><p>Эти значения станут устаревшими по мере эволюции ваших данных.</p></li><li><p>Этот параметр будет применяться ко всем шаффлингах в вашем запросе.</p></li></ul><p>Перед первым этапом в предыдущем примере известно распределение и объем данных, и Spark может предложить разумное значение для количества партиций. Однако для второго этапа эта информация еще не известна, так как цена, которую нужно заплатить за ее получение, - это выполнение фактической обработки на первом этапе: отсюда и обращение к магическому числу.</p><h3>Принцип работы Adaptive Query Execution</h3><p>Основная идея AQE состоит в том, чтобы сделать план выполнения не окончательным и перепроверять статус после каждого этапа. Таким образом, план выполнения разбивается на новые абстракции «этапов запроса», разделенных этапами.</p><p>Catalyst теперь останавливается на границе каждого этапа, чтобы попытаться применить дополнительную оптимизацию с учетом информации, доступной на основе промежуточных данных.</p><p>Поэтому AQE можно определить как слой поверх Spark Catalyst, который будет изменять план Spark ""на лету"".</p><p>Есть недостатки? Некоторые есть, но они второстепенные:</p><ul><li><p>Выполнение останавливается на границе каждого этапа, чтобы Spark проверил свой план, но это компенсируется увеличением производительности.</p></li><li><p>Пользовательский интерфейс Spark труднее читать, потому что Spark создает для данного приложения больше заданий, и эти задания не подхватывают группу заданий и описание, которое вы задали.</p></li></ul><h3>Адаптивное количество перемешиваемых партиций</h3><p>Эта функция AQE доступна, начиная с версии Spark 2.4.</p><p>Чтобы включить ее, вам нужно установить для spark.sql.adaptive.enabled значение true, значение по умолчанию - false. Когда AQE включено, количество партиций в случайном порядке регулируется автоматически и больше не равно 200 по умолчанию или заданному вручную значению.</p><p>Вот как выглядит выполнение первого запроса TPC-DS до и после включения AQE:</p><figure class=""""><img alt="""" height=""682"" src=""https://habrastorage.org/getpro/habr/upload_files/74b/a1b/d14/74ba1bd1417f20a2617c8826e9db3287.png"" title="""" width=""1600""/><figcaption></figcaption></figure><h4>Динамическая конвертация Sort Merge Joins в Broadcast Joins</h4><p>AQE преобразует соединения sort-merge в broadcast хэш-соединения, если статистика времени выполнения любой из сторон соединения меньше порога broadcast хэш-соединения.</p><p>Вот как выглядят последние этапы выполнения второго запроса TPC-DS до и после включения AQE:</p><figure class=""""><img height=""427"" src=""https://habrastorage.org/getpro/habr/upload_files/1ba/27d/d40/1ba27dd4001871b1d7b1508d6e00d9c4.png"" width=""1600""/><figcaption></figcaption></figure><h3>Динамическое объединение shuffle партиций</h3><p>Если количество разделов в случайном порядке больше, чем количество групп по ключам, то много циклов ЦП теряется из-за несбалансированного распределения ключей.</p><p>Когда оба: </p><p>·         spark.sql.adaptive.enabled и</p><p>·         spark.sql.adaptive.coalescePartitions.enabled </p><p>установлены на true, Spark объединит смежные перемешанные разделы в соответствии с целевым размером, указанным в spark.sql.adaptive.advisoryPartitionSizeInBytes. Это делается, чтобы избежать слишком большого количества мелких задач.</p><figure class=""""><img height=""365"" src=""https://habrastorage.org/getpro/habr/upload_files/02e/992/0d6/02e9920d6ae9eee6b934eafc1bbc07c8.png"" width=""512""/><figcaption></figcaption></figure><h3>Динамическая оптимизация обьединений с перекосом</h3><p>Skew (перекос) - это камень преткновения распределенной обработки. Это может задержать обработку буквально на несколько часов:</p><figure class=""""><img height=""110"" src=""https://habrastorage.org/getpro/habr/upload_files/81f/923/98b/81f92398b5de593c319bfa51ccfce05c.png"" width=""512""/><figcaption></figcaption></figure><p>Без оптимизации время, необходимое для выполнения объединения, будет определяться самым большим разделом.</p><figure class=""""><img height=""188"" src=""https://habrastorage.org/getpro/habr/upload_files/a50/b4f/d8c/a50b4fd8c7491ba8c0eb1b8a4358e3ac.png"" width=""512""/><figcaption></figcaption></figure><p>Оптимизация skew join, таким образом, разобъет раздел A0 на подразделы, используя значение, указанное park.sql.adaptive.advisoryPartitionSizeInBytes, и присоединит каждый из них к соответствующему разделу B0 таблицы B.</p><figure class=""""><img height=""630"" src=""https://habrastorage.org/getpro/habr/upload_files/bb4/8d1/fb1/bb48d1fb1bced5d4077439832415824e.png"" width=""1600""/><figcaption></figcaption></figure><p>Следовательно, вам необходимо предоставить AQE свое определение перекоса.</p><p>Это включает в себя два параметра:</p><p>1.   spark.sql.adaptive.skewJoin.skewedPartitionFactor является относительным: партиция считается с пересом, если ее размер больше, чем этот коэффициент, умноженный на средний размер партиции, а также, если он больше, чем</p><p>2.   spark.sql.adaptive.skewedPartitionThresholdInBytes, который является абсолютным: это порог, ниже которого перекос будет игнорироваться.</p><h3>Динамическое сокращение разделов</h3><p>Идея динамического сокращения разделов (dynamic partition pruning, DPP) - один из наиболее эффективных методов оптимизации: считываются только те данные, которые вам нужны. Если в вашем запросе есть DPP, то AQE не запускается. DPP было перенесено в Spark 2.4 для CDP.</p><p>Эта оптимизация реализована как на логическом, так и на физическом уровне.</p><p>1.   На логическом уровне фильтр размера идентифицируется и распространяется через обьединение на другую часть сканирования.</p><p>2.   Затем на физическом уровне фильтр выполняется один раз в части измерения, и результат транслируется в основную таблицу, где также применяется фильтр.</p><figure class=""""><img height=""709"" src=""https://habrastorage.org/getpro/habr/upload_files/5e8/e5d/288/5e8e5d288d62131e77350bd0c7abba88.png"" width=""1600""/><figcaption></figcaption></figure><p>DPP в действительности может работать с другими типами обьединений (например, SortMergeJoin), если вы отключите spark.sql.optimizer.dynamicPartitionPruning.reuseBroadcastOnly.</p><p>В этом случае Spark оценит, действительно ли фильтр DPP улучшает производительность запроса.</p><p>DPP может привести к значительному увеличению производительности высокоселективных запросов, например, если ваш запрос фильтрует данные за один месяц из выборки за 5 лет.</p><figure class=""""><img height=""989"" src=""https://habrastorage.org/getpro/habr/upload_files/dda/c4c/d7d/ddac4cd7dd86b279a1352619d8621a11.png"" width=""1600""/><figcaption></figcaption></figure><p>Не все запросы получают такой впечатляющий прирост производительности, но 72 из 99 запросов TPC-DS положительно влияют на DPP.</p><h3>Заключение  </h3><p>Spark прошел долгий путь от своей первоначальной базовой парадигмы: неспешного выполнения оптимизированного статического плана для статического набора данных.</p><p>Анализ статического набора данных был пересмотрен из-за потоковой передачи: команда Spark сначала создала довольно неуклюжий дизайн на основе RDD, прежде чем придумать лучшее решение с использованием DataFrames.</p><p>Часть статического плана подверглась сомнению со стороны SQL, а структура адаптивного выполнения запросов в некотором роде - это то, чем является структурированная потоковая передача для исходной потоковой библиотеки: элегантное решение, которым она должна была быть с самого начала.</p><p>Благодаря фреймворку AQE, DPP, усиленной поддержке графических процессоров и Kubernetes перспективы увеличения производительности теперь весьма многообещающие, поэтому мы и наблюдаем повсеместный переход на Spark 3.1</p></div>"
2,2021-06-01 11:14:00,Генераторы для самых маленьких,https://habr.com/ru/company/domclick/blog/560300/,"<div class=""post__text post__text_v2"" id=""post-content-body""><p>Всем привет! В бытность мою, когда я самостоятельно изучал Python, я находил достаточно теоретического материала о языке и его возможностях. Однако даже после прочтения нескольких статей на разных сайтах и книг многое не укладывались у меня в голове (да, вот такой вот я тугой). Непонятные концепции приходилось зубрить «на веру» без глубокого понимания, потому что практические примеры в статьях были для меня сложны. Время шло, я становился опытнее, понимание приходило на практических задачах, и в какой-то момент я стал учить Python'у своих друзей. В рамках наставничества я обнаружил, что, кажется, наметил путь, по которому можно объяснять сложные концепции простыми словами.</p><p>С уважением ко всему IT-сообществу в День защиты детей и в надежде на то, что смогу помочь новичкам понять прелесть и пользу сложных и непонятных на первый взгляд вещей, пишу свою дебютную статью.</p><p>Сегодня хочется ещё раз поговорить о генераторах. Итак, в бой!</p><h3>Разберёмся с понятиями и поставим задачу</h3><p>Первое, о чем стоит всегда помнить, когда кто-то заговаривает с вами о генераторах в Python: не стоит путать «генераторы коллекций» (comprehensions, они же «включения») и «генераторы-итераторы». Первые — мощный синтаксический сахар для генерации коллекций «на лету», вторые  — способ получения значений по запросу. Речь сегодня пойдёт о вторых.</p><p>Давайте представим, что мы попали в ту самую сказку, где тот самый паренёк Вовка говорил: «И так сойдёт!» Только вот того паренька уже давно нет, а какая-нибудь Василиса Премудрая в обмен на путь домой подкидывает нам работёнки.</p><figure class=""float""><img alt=""Время засучить рукава и выбрать правильные инструменты."" height=""1552"" src=""https://habrastorage.org/getpro/habr/upload_files/a2c/0a7/f7d/a2c0a7f7d5f79cc5401908ad0d75527c.png"" title=""Время засучить рукава и выбрать правильные инструменты."" width=""2236""/><figcaption>Время засучить рукава и выбрать правильные инструменты.</figcaption></figure><p><strong><em>Задача:</em></strong> <em>надо организовать периодический (например, ежедневный, ежечасный и т.д.) процесс кормления трёх подопытных с помощью скатерти-самобранки. Скатерть-самобранка каждый раз имеет разное количество зарядов еды в своей «обойме». Чувство голода каждого из подопытных точно так же непостоянно (в один момент подопытный может испытывать чувство голода на 3 из 10, а спустя какое-то время</em> <em>—</em> <em>хотеть еды на все 10).</em></p><p>Подопытных кормим в порядке приоритета: сначала первого, затем второго, после этого третьего. Каждого будем кормить до отвала. То есть до тех пор, пока первый не наестся, мы не переходим ко второму, а от второго не переходим к третьему.</p><h3>Подступаемся к решению</h3><p>Очевидно, что кормить наших подопытных мы можем двумя способами:</p><ol><li><p>Банкетный способ. Сразу вывалить на скатерть всю еду и подпускать каждого из подопытных к ней по очереди.</p></li><li><p>Буфетный способ. По очереди подпускать подопытных и отдавать очередную единицу еды только по запросу.</p></li></ol><h3>Первый путь</h3><p>Мы вывалили всю еду на скатерть и приглашаем подопытных трапезничать по очереди. Возможно два варианта развития событий: либо вся еда будет съедена без остатка, либо что-то всё-таки останется и не будет использовано. Это примерно так же, как когда вы (да-да, именно вы, мои маленькие обжоры) заказываете в ресторане столько еды, сколько не можете потом съесть и что-то потом приходится выбрасывать. При этом на приготовление еды потрачены ресурсы и, более того, она занимает место на столе. А ещё вы вполне очевидно переплатили за свой ужин. Короче говоря, плохо всем с точки зрения разумной экономии :)</p><p><strong>От скатерти к памяти:</strong></p><figure class=""float""><img alt=""Весь ассортимент накрыт на стол, просто потому что скатерть так может."" height=""1798"" src=""https://habrastorage.org/getpro/habr/upload_files/ef4/c58/6aa/ef4c586aa07b2a9f8999f6f258b2de45.png"" title=""Весь ассортимент накрыт на стол, просто потому что скатерть так может."" width=""2244""/><figcaption>Весь ассортимент накрыт на стол, просто потому что скатерть так может.</figcaption></figure><p>Так вот, я думаю, что пытливые хозяйки и хозяева уже обратили внимание на то, что пример со скатертью иллюстрирует задействование ресурсов для решения поставленной задачи. В нашем примере за объём памяти на хранение элементов коллекции отвечает площадь, занимаемая каждым блюдом на скатерти. Желая накрыть на стол сразу всё доступное «меню», мы обрекаем себя на то, что будет потрачено время на приготовление всего ассортимента блюд, вне зависимости от того, съест их кто-то или нет. Прямо как на банкете.</p><p>Изобразим наш банкет с накрытой по полному ассортименту скатертью в виде таблицы:</p><div><div class=""table""><table><tbody><tr><td colspan=""3"" data-colwidth=""0,246,0"" width=""0""><p align=""center""><strong>СХЕМА БЛЮД СКАТЕРТИ-САМОБРАНКИ С ПОКАЗАТЕЛЯМИ РЕСУРСОЗАТРАТНОСТИ</strong></p></td></tr><tr><td><p><strong>СЕЛЬДЬ ПОД ШУБОЙ</strong></p><p><strong><sup>20 ед. площади</sup></strong></p><p><strong><sup>40 ед. времени</sup></strong></p></td><td data-colwidth=""246"" width=""246""><p><strong>БОРЩ</strong></p><p><strong><sup>30 ед. площади</sup></strong></p><p><strong><sup>50 ед. времени</sup></strong></p></td><td><p><strong>ХЛЕБ</strong></p><p><strong><sup>25 ед. площади</sup></strong></p><p><strong><sup>5 ед. времени</sup></strong></p></td></tr><tr><td><p><strong>МОРС</strong></p><p><strong><sup>15 ед. площади</sup></strong></p><p><strong><sup>35 ед. времени</sup></strong></p></td><td data-colwidth=""246"" width=""246""><p><strong>ОЛИВЬЕ</strong></p><p><strong><sup>10 ед. площади</sup></strong></p><p><strong><sup>25 ед. времени</sup></strong></p></td><td><p><strong>РЫБА</strong></p><p><strong><sup>30 ед. площади</sup></strong></p><p><strong><sup>35 ед. времени</sup></strong></p></td></tr><tr><td><p><strong>ПИРОГ</strong></p><p><strong><sup>30 ед. площади</sup></strong></p><p><strong><sup>50 ед. времени</sup></strong></p></td><td data-colwidth=""246"" width=""246""><p><strong>ОКРОШКА</strong></p><p><strong><sup>20 ед. площади</sup></strong></p><p><strong><sup>15 ед. времени</sup></strong></p></td><td><p><strong>КАРТОШКА</strong></p><p><strong><sup>15 ед. площади</sup></strong></p><p><strong><sup>15 ед. времени</sup></strong></p></td></tr></tbody></table></div></div><p>Теперь перейдём к терминам Python. В качестве уже накрытой скатерти у нас будет выступать какая-либо коллекция элементов. Давайте возьмём список с числами от 0 до 100 000 000.</p><p>Размер такого списка составляет 859 724 472 байт, а его создание занимает около 6 секунд на моей машине. А теперь представьте, что наши подопытные не слишком-то голодны и не способны скушать всё, что мы им предложили. А теперь представьте, что групп подопытных может быть несколько, да и период трапез может изменяться. А каждая такая трапеза будет расходовать память и время процессора. И тут мы видим очевидную проблему: нерациональное использование ресурсов. Как же быть?</p><h4>Менее сказочный пример из классического мира</h4><figure class=""float""><img alt=""Умный дом бывает не только в сказках"" height=""1800"" src=""https://habrastorage.org/getpro/habr/upload_files/a92/90a/860/a9290a86036eb84f9d0bb33309f5f9f7.png"" title=""Умный дом бывает не только в сказках"" width=""2222""/><figcaption>Умный дом бывает не только в сказках</figcaption></figure><p>Прежде чем рассмотреть второй вариант «кормления» рассмотрим более технологичный пример похожего сценария. Представьте себе, что каждый день наш клиент n раз получает извне параметр, на основе которого вычисляется коллекция с какими-то элементами. Дальше эти элементы мы распределяем по нескольким потребителям для выполнения какой-либо бизнес-логики. К примеру, логики приоритетного распределения ресурсов между какими-то узлами Умного Дома. Наш дом без проблем обойдётся без постоянно включённого кондиционера или умной колонки, но мы бы не хотели оставлять жилище без пожарной сигнализации или системы охраны.</p><h3>Второй путь</h3><p>Как было показано выше, кормить наших подопытных, вываливая всё сразу на стол, — дорого и не слишком умно. Поэтому мы поступим следующим образом: каждый участник эксперимента будет подходить к скатерти и нажимать на ней специальную кнопку с надписью <code>next</code>, которая будет готовить и выдавать следующее для потребления блюдо.</p><p>Очевидно, что для одного блюда места нужно сильно меньше, нежели для всех сразу. А это значит, что затраты памяти будут разительно ниже. После того, как первый подопытный наестся, мы сможем пригласить к столу второго, а затем третьего. И даже если у нас в скатерти останется ещё практически полная пачка зарядов, это никак не будет нас тормозить.</p><p>Кстати, ларец на этой картинке работает по тому же принципу, что и скатерть с кнопкой next: из него по команде могут вылезти два бравых парня, а затем куча еды</p><p>Возвращаясь к примеру с Умным Домом: представьте, что нам пришла информация о доступности 100 000 000 элементов коллекции для использования узлами нашей системы. Пожарная сигнализация в данный момент готова потребить 2 элемента этой коллекции, система охраны — 10, а остальное уйдет кондиционеру (5) и умной колонке (3). При этом в пуле элементов исходной коллекции останется ещё очень много неизрасходованных «зарядов».</p><figure class=""float""><img alt=""Разработчик приложения делает свой заказ"" height=""1800"" src=""https://habrastorage.org/getpro/habr/upload_files/9cf/abb/186/9cfabb1866f8c6b96ef07365dfb0dd55.png"" title=""Разработчик приложения делает свой заказ"" width=""2240""/><figcaption>Разработчик приложения делает свой заказ</figcaption></figure><p>Так вот, подобный объект с кнопкой next и есть ни что иное, как объект-генератор. При использовании объектов-генераторов та же самая упакованная коллекция из 100 000 000 элементов занимает всего 120 байт (в некоторых случаях и при использовании некоторых встроенных инструментов — даже меньше), а на сборку такого объекта на моей машине ушло 0,00009 секунды. По сути, мы говорим о том, что у человека есть в руках меню, которое может приготовить заведение (в нашем случае — скатерть), и готовить блюда кухня начнёт только при прямом заказе.</p><p><strong>Хозяйке на заметку:</strong></p><ul><li><p>Объекты-генераторы не дают выигрыша по времени и памяти в том случае, если вам нужно хранить и работать сразу со всеми элементами коллекции, а не только с каким-то одним. Например, если хочется сфотографироваться на фоне банкетного стола со всей едой самобранки, то это та самая история.</p></li><li><p>Объекты-генераторы не дают выигрыша по времени, если вы последовательно запрашиваете все элементы, которые могут быть получены. То есть если вы точно знаете, что вся еда будет съедена. При этом выигрыш по памяти останется.</p></li></ul><h3>Ближе к коду</h3><p>А теперь попробуем реализовать оба наших подхода в виде кода на Python. Итак, роль скатерти-самобранки у нас будет играть функция, которая на вход принимает количество зарядов еды и возвращает список с числами от 0 до n.</p><p>Роль подопытных сыграют три функции, которые на вход будут принимать лист с элементами (едой). Каждый из подопытных будет выводить сообщение о том, что он употребил в пищу очередной элемент с каким-то результатом. Пускай первый просто выводит на экран употребляемый в пищу элемент, второй перед показом умножает его на 4, а третий преобразует его в строку и умножает её на 2 с последующим выводом. Для большей наглядности давайте предварительно переводить исходные элементы в строковый тип.</p><pre><code class=""python"">def skat(n): 
    """"""Функция, которая возвращает последовательность от 0 до n"""""" 
    # сознательно не используем тут range, потому как range является объектом-итератором.
    res = []
    cnt = 0
    while cnt &lt; n:
        res.append(cnt)
        cnt += 1
    return res

def first_eater(eda_list): 
""""""Первый подопытный"""""" 
    for eda in eda_list: 
        print(f""Первый подопытный съел {eda} и написал: "", str(eda)) 
      
      
def second_eater(eda_list): 
""""""Второй подопытный"""""" 
    for eda in eda_list: 
        print(f""Второй подопытный съел {eda} и написал: "", str(eda) * 4) 
      
      
def third_eater(eda_list): 
""""""Второй подопытный"""""" 
    for eda in eda_list: 
        print(f""Третий подопытный съел {eda} и написал: "", str(eda) * 10)
      
      
# заряжаем скатерть
eda_list = skat(100_000_000) 
# задаём параметры голода
golod_1 = 2 
golod_2 = 3 
golod_3 = 4 
# кормим
first_eater(eda_list[:golod_1])
second_eater(eda_list[golod_1:golod_2 + golod_1])
third_eater(eda_list[golod_2 + golod_1:golod_2 + golod_1 + golod_3])

# результат, который будет выведен в консоль:
# &gt;&gt;&gt; Первый подопытный съел 0 и написал:  0
# &gt;&gt;&gt; Первый подопытный съел 1 и написал:  1
# &gt;&gt;&gt; Второй подопытный съел 2 и написал:  2222
# &gt;&gt;&gt; Второй подопытный съел 3 и написал:  3333
# &gt;&gt;&gt; Второй подопытный съел 4 и написал:  4444
# &gt;&gt;&gt; Третий подопытный съел 5 и написал:  5555555555
# &gt;&gt;&gt; Третий подопытный съел 6 и написал:  6666666666
# &gt;&gt;&gt; Третий подопытный съел 7 и написал:  7777777777
# &gt;&gt;&gt; Третий подопытный съел 8 и написал:  8888888888</code></pre><p>Как можно заметить, помимо затрат по памяти и времени у нашего кода есть существенный недостаток: он не самым лучшим образом выглядит. Проблема состоит в том, что нашим подопытным нужно давать именно тот кусок нашего списка, который они должны употребить. Это существенно снижает гибкость кода. Если подопытных станет больше или меньше, то правки необходимо будет внести сразу в несколько мест, и довольно легко запутаться в срезах. Либо, как вариант, изменять исходный список внутри функций, делая <code>pop</code> очередного значения, но тут придётся помнить об особенностях хранения ссылок на другие объекты в списках (кортежах и словарях), что тоже не благоприятствует прозрачности кода.</p><h3>Интермеццо перед разбором кодовой базы второго варианта</h3><p>Итак, мы поняли, что первый вариант — не самый лучший для использования. Как же быть? Обо всём по порядку. Любая функция возвращает какой-то результат явно (<code>return</code> что-нибудь конкретное) или неявно (когда <code>return</code> не прописано и возвращается <code>None</code>). Так вот, в Python есть ещё одно ключевое слово помимо <code>return</code>, которое позволяет возвращать значения — <code>yield</code>.</p><p>Давайте взглянем вот на такие две функции, которые синтаксически отличаются только ключевыми словами для возврата значений:</p><pre><code class=""python"">def my_func_1():
  print(""Сейчас отдам число"")
  return 1


def my_func_2():
  print(""Сейчас отдам число"")
  yield 1</code></pre><p>Давайте попробуем вывести эти функции на печать (именно функции, а не результат, который они возвращают):</p><pre><code class=""python"">print(my_func_1)
print(my_func_2)

# результат, который будет выведен в консоль:
# &gt;&gt;&gt; &lt;function my_func_1 at 0x10c399950&gt;
# &gt;&gt;&gt; &lt;function my_func_2 at 0x10c3a4290&gt;</code></pre><p>Иначе говоря, с точки зрения интерпретатора <code>my_func_1</code> и <code>my_func_2</code> ничем не отличаются друг от друга, если мы говорим про тип объекта. Это две функции. Однако дело приобретает иной оборот, когда мы пытаемся запустить исполнение и посмотреть возвращаемый результат:</p><pre><code class=""python"">print(my_func_1())
print(my_func_2())

# результат, который будет выведен в консоль
# &gt;&gt;&gt; Сейчас отдам число
# &gt;&gt;&gt; 1
# &gt;&gt;&gt; &lt;generator object my_func_2 at 0x108a702d0&gt;</code></pre><blockquote><p>«Что это за безобразие во втором случае?» — скажете вы.</p><p>«Всё под контролем!» — отвечу вам я.</p></blockquote><p>Дело в том, что интерпретатор при исполнении самой функции в случае, если в ней присутствует ключевое слово <code>yield</code>, ВСЕГДА возвращает объект-генератор (<code>generator-object</code>). По сути, объект-генератор — это собранная коробочка, которая с радостью выполнит то, что вы описали в теле своей функции. Но только по запросу! То есть мы получим нашу единичку не из самой функции, а из объекта-генератора, который нам вернула <code>my_func_2</code>.</p><p>Как будем доставать нашу единичку? Очень просто! В Python есть встроенная функция <code>next</code> (помните кнопку на скатерти, про которую я писал выше?), которая на вход принимает объект-генератор (на самом деле объект-итератор, но пока не будем об этом, чтобы не усложнять) и выполняет код до следующего <code>yield</code> с возвращением того, что написано сразу после этого самого <code>yield</code>. Давайте проверим это:</p><pre><code class=""python"">print(next(my_func_2()))

# результат, который будет выведен в консоль:
# &gt;&gt;&gt; 1</code></pre><p>Вуаля! А вот и наша единичка! Но что означает «...и выполняет код до следующего <code>yield</code>...»? А это означает то, что в теле функции, описывающей правило, по которому наш объект-генератор будет отдавать результат, может быть сразу несколько <code>yield</code>! Давайте чуть-чуть поменяем поведение <code>my_func_2</code> и добавим ещё один <code>yield</code>: </p><pre><code class=""python"">def my_func_2():
    print(""Сейчас отдам число"") 
    yield 1 
    print(""Сейчас отдам ещё число"") 
    yield 2 
    print(""Больше ничего нету!"")

# попробуем выполнить вот такой код:
gen_o = my_func_2() # тут у нас будет создан и записан в переменную generator-object

print(next(gen_o))
print(""Ого, мы только что получили число из объекта-генератора по запросу!"") 
print(next(gen_o))

# результат, который будет выведен в консоль:
# &gt;&gt;&gt; Сейчас отдам число
# &gt;&gt;&gt; 1
# &gt;&gt;&gt; Ого, мы только что получили число из объекта-генератора по запросу!
# &gt;&gt;&gt; Сейчас отдам ещё число
# &gt;&gt;&gt; 2</code></pre><p>Как вы могли заметить, интерпретатор действительно при каждой передаче нашего <code>generator-object</code> в функцию <code>next</code> выполнил код до ближайшего <code>yield</code>. При этом и в первом, и во втором вызове <code>next</code> мы работали с одним и тем же объектом. Очередное значение как бы «отстреливается», словно пуля из пистолета при нажатии на спуск. Более того, обратите внимание, что мы получили первое значение из <code>generator-object</code>, а дальше вернулись в основной контекст исполнения программы. Это открывает огромные возможности! Но об этом поговорим в следующих сериях.</p><p>Теперь давайте дополним наш код третьим вызовом <code>next</code> и взглянем на результат:</p><pre><code class=""python"">gen_o = my_func_2()
print(next(gen_o))
print(""Ого, мы только что получили число из объекта-генератора по запросу!"")
print(next(gen_o))
print(next(gen_o))

# результат, который будет выведен в консоль:
# &gt;&gt;&gt; 1
# &gt;&gt;&gt; Ого, мы только что получили число из объекта-генератора по запросу!
# &gt;&gt;&gt; Сейчас отдам ещё число
# &gt;&gt;&gt; 2
# &gt;&gt;&gt; Больше ничего нету!
# &gt;&gt;&gt; Traceback (most recent call last):
# &gt;&gt;&gt; File ""&lt;путь исполняемого файла&gt;"", line 13, in &lt;module&gt;
# &gt;&gt;&gt; print(next(gen_o))
# &gt;&gt;&gt; StopIteration</code></pre><p>Только что интерпретатор сообщил нам о том, что мы «отстреляли» свой <code>generator-object</code>. Иначе говоря, у нас больше нет <code>yield</code>, до которых можно было бы дойти. Если наш объект-генератор больше не имеет зарядов, а мы всё равно пытаемся получить новое значение, то возбуждается исключение <code>StopIteration</code>.</p><p><strong>Хозяйке на заметку:</strong> <code>generator-object</code> можно «отстрелять» только один раз и только вперёд. Вернуться в прошлое или каким-то образом «обнулить» его нельзя. Подробнее такие сценарии стоит рассмотреть в отдельной статье про итераторы. Для <code>generator-object</code> предполагается, что при необходимости мы просто запустим нашу функцию <code>my_func_2</code> ещё раз и получим новенький объект для работы.</p><figure class=""float""><img alt='Генератор смотрит на тебя, как бы спрашивая ""Что будем заказывать?""' height=""484"" src=""https://habrastorage.org/getpro/habr/upload_files/ce2/890/eb8/ce2890eb894bb39d1bfb22d97d665061.jpeg"" title='Генератор смотрит на тебя, как бы спрашивая ""Что будем заказывать?""' width=""773""/><figcaption>Генератор смотрит на тебя, как бы спрашивая ""Что будем заказывать?""</figcaption></figure><p>А пока что вернемся к нашим подопытным и скатерти. Всё, что нам теперь требуется, это написать всё те же несколько функций. Для скатерти это будет функция, принимающая на вход всё то же число n, только теперь она должна возвращать очередное значение по запросу. А наши подопытные на вход теперь будут принимать не лист, а <code>generator-object</code>, который будет произведен функцией скатерти-самобранки, а также параметр голода:</p><pre><code class=""python"">def skat(n):
    """"""Функция, которая возвращает объект-генератор, способный предоставить нам 
    элементы по запросу от 0 до n""""""
    cnt = 0
    while cnt &lt; n:
        yield cnt
        cnt += 1


def first_eater(golod, skat):
    """"""Первый подопытный""""""
    while golod &gt; 0:
        eda = next(skat)
        print(f""Первый подопытный съел {eda} и в результате написал: "", eda)
        golod -= 1


def second_eater(golod, skat):
    """"""Второй подопытный""""""
    eda = next(skat)
    while golod &gt; 0:
        print(f""Второй подопытный съел {eda} и в результате написал: "", str(eda) * 4)
        golod -= 1


def third_eater(golod, skat):
    """"""Третий подопытный""""""
    eda = next(skat)
    while golod &gt; 0:
        print(f""Третий подопытный съел {eda} и в результате написал: "", str(eda) * 10)
        golod -= 1


skat_gen_obj = skat(100_000_000)
golod_1 = 2
golod_2 = 3
golod_3 = 4

try:
    first_eater(golod_1, skat_gen_obj)
    second_eater(golod_2, skat_gen_obj)
    third_eater(golod_3, skat_gen_obj)
except StopIteration:
    print(""Заряды в скатерти кончились!"")

# результат, который будет выведен в консоль:
# &gt;&gt;&gt; Первый подопытный съел 0 и в результате написал:  0
# &gt;&gt;&gt; Первый подопытный съел 1 и в результате написал:  1
# &gt;&gt;&gt; Второй подопытный съел 2 и в результате написал:  2222
# &gt;&gt;&gt; Второй подопытный съел 2 и в результате написал:  2222
# &gt;&gt;&gt; Второй подопытный съел 2 и в результате написал:  2222
# &gt;&gt;&gt; Третий подопытный съел 3 и в результате написал:  3333333333
# &gt;&gt;&gt; Третий подопытный съел 3 и в результате написал:  3333333333
# &gt;&gt;&gt; Третий подопытный съел 3 и в результате написал:  3333333333
# &gt;&gt;&gt; Третий подопытный съел 3 и в результате написал:  3333333333</code></pre><p>Обрамляем процесс кормления наших подопытных в блок <code>try - except</code> на тот самый случай, если будем иметь дело с дефицитом еды. При желании можно внести этот блок в каждую из функций, чтобы не выносить его в основной контекст выполнения, но я оставлю это на откуп тем, кто захочет поэкспериментировать с моей кодовой базой.</p><figure class=""float""><img alt=""Недальновидный разработчик пытается получить всю коллекцию, хотя ему нужно только пару элементов оттуда "" height=""1564"" src=""https://habrastorage.org/getpro/habr/upload_files/ee2/890/cf8/ee2890cf81553ffe1725bd93aad1e8d7.png"" title=""Недальновидный разработчик пытается получить всю коллекцию, хотя ему нужно только пару элементов оттуда "" width=""2254""/><figcaption>Недальновидный разработчик пытается получить всю коллекцию, хотя ему нужно только пару элементов оттуда </figcaption></figure><p>Написанный выше код существенно лучше поддерживается и нам не нужно держать в памяти всю «еду» (обычно это приводит к тому, что на картинках). Кроме того, все наши подопытные работают с одним и тем же объектом без дополнительных усложнений, как в случае со списком, где нам вынужденно пришлось использовать срезы. Если у нас увеличится или уменьшится количество подопытных, то нам не важно, как много их будет, пускай даже миллион (ну, тут уже надо будет дописать генератор «подопытных» :D)  — достаточно будет передать нашим подопытным актуальный <code>generator-object</code>.</p><figure class=""""><img alt=""Недальновидный разработчик смотрит на метрики использования памяти своего кода, в котором в типовой ситуации не были использованы объекты-генераторы"" height=""1560"" src=""https://habrastorage.org/getpro/habr/upload_files/6a6/e01/8da/6a6e018da7be1b48d6b064f1d309b1a5.png"" title=""Недальновидный разработчик смотрит на метрики использования памяти своего кода, в котором в типовой ситуации не были использованы объекты-генераторы"" width=""2242""/><figcaption>Недальновидный разработчик смотрит на метрики использования памяти своего кода, в котором в типовой ситуации не были использованы объекты-генераторы</figcaption></figure><p>На этом рассказ про объекты-генераторы подходит к концу. Я раскрыл не все их тайны, но об этом можно поговорить в следующих сериях.</p><h3>Вместо выводов</h3><p>Мы успешно справились с заданием и Василиса-премудрая открывает нам портал для возвращения домой. Это был хороший опыт.</p><p>Объекты-генераторы являются мощным инструментом, который позволяет в некоторых случаях экономить значительное количество памяти и времени, при этом повышая гибкость кодовой базы.</p><p>Если вы имеете дело с задачей, при которой:</p><ul><li><p>предполагается работа с коллекцией, элементы которой могут быть описаны с помощью некого правила их генерации</p><p>и</p></li><li><p>предполагается работа с коллекцией поэлементно или с выборкой, размер которой сильно меньше общего количества всех элементов коллекции и вы не завязаны на конкретные позиции этих элементов в ней, а просто на факт получения этих элементов</p><p>а может быть, ко всему прочему:</p></li><li><p>имеете необходимость скармливать коллекцию в качестве топлива для неких потребителей, то</p></li></ul><p><strong><em>Объекты-генераторы</em></strong> <strong>—<em> это альтернатива, которая вам нужна!</em></strong></p><p>Если вы имеете дело с задачей, при которой:</p><ul><li><p>вы точно знаете, что предполагается работа сразу со всеми элементами коллекции (или подавляющим большинством) и, как следствие, нужно хранить коллекцию в памяти целиком, то</p></li></ul><p><strong><em>Лучше использовать другие типы данных коллекций: списки, кортежи, множества и т.д.</em></strong></p><figure class=""""><img alt=""Разработчик, который научился пользоваться объектами-генераторами."" height=""1800"" src=""https://habrastorage.org/getpro/habr/upload_files/5a4/229/f39/5a4229f397fc17e44e0d8684730dd1fb.png"" title=""Разработчик, который научился пользоваться объектами-генераторами."" width=""2244""/><figcaption>Разработчик, который научился пользоваться объектами-генераторами.</figcaption></figure><p>Если вы дочитали до этого места, спасибо вам большое! Надеюсь, что новички в языке сочтут мою статью полезной, а опытные — занимательной). В следующей статье хочется раскрыть тему объектов-итераторов с точки зрения того, как они используются в цикле <code>for</code>, и перейти к разбору итераторов.</p></div>"
